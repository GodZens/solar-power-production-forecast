{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478227c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import read_CWB_3H as cwb\n",
    "import read_OWM_3H as owm\n",
    "# import read_TCW_1H as twc\n",
    "## 在線使用設置##############\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data(start):\n",
    "    start_date, end_date = start-datetime.timedelta(days=1), start+datetime.timedelta(days=2)\n",
    "    # cwb\n",
    "    # 打包 1 小時預報資料\n",
    "    forecast = cwb.aggregate_data2(start_date,end_date)\n",
    "    # 合併新舊預報資料，並儲存至本地資料夾\n",
    "    cwb.merge_with_history(forecast)\n",
    "\n",
    "    # twc\n",
    "    forecast = twc.aggregate_data2(start_date,end_date)\n",
    "    print(forecast)\n",
    "    if(forecast !=None):\n",
    "        drop = twc.sort_data_3h()\n",
    "        twc.merge_data_24(drop)\n",
    "        twc.data_to_3hour()\n",
    "\n",
    "    # owm\n",
    "    forecast = owm.aggregate_data2(start_date,end_date)\n",
    "    drop = owm.sort_data_3h()\n",
    "    owm.merge_data_24(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_MSM(data,last_time):\n",
    "    msm = pd.read_csv('./MSM_data/save/solar_汙水廠_dswrfpred.csv')\n",
    "    msm['TIME_TO_INTERVAL'] = pd.to_datetime(msm['TIME_TO_INTERVAL'])\n",
    "    mask = (msm['TIME_TO_INTERVAL'] >= last_time)\n",
    "    msm = msm[mask]\n",
    "    msm = msm.sort_values(by='TIME_TO_INTERVAL').reset_index(drop=True)\n",
    "    msm = msm.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\")\n",
    "    msm['TIME_TO_INTERVAL'] = pd.to_datetime(msm['TIME_TO_INTERVAL'])\n",
    "#     data['TIME_TO_INTERVAL'] = pd.to_datetime(data['TIME_TO_INTERVAL'])\n",
    "#     msm1 = msm[~msm['Radiation(MSMv4)[1d]'].isna()][['TIME_TO_INTERVAL','Radiation(MSMv4)[1d]']]\n",
    "#     msm2 = msm[~msm['Radiation(MSMv4)[2d]'].isna()][['TIME_TO_INTERVAL','Radiation(MSMv4)[2d]']]\n",
    "\n",
    "    data['Radiation(MSM)'] = np.nan\n",
    "    data['Radiation(MSM)'] = data.apply(lambda x: put_msm_data(x, msm, 'Radiation(MSMv4)[1d]','Radiation(MSMv4)[2d]','Radiation(MSMv4)[3d]','Radiation(MSMv4)[4d]'), axis=1)\n",
    "    total_data = data.sort_values(by='TIME_TO_INTERVAL')\n",
    "    \n",
    "    return total_data\n",
    "\n",
    "def put_msm_data(row, msm, feature, feature_2,feature_3,feature_4):\n",
    "    r = msm['TIME_TO_INTERVAL'].eq(row['TIME_TO_INTERVAL'])\n",
    "    if ((len(msm[r][feature]>0)) and (msm[r][feature].isnull().values.any() == False) ):\n",
    "        return msm[r][feature].values[0]/1000\n",
    "    \n",
    "    elif((len(msm[r][feature_2]>0)) and (msm[r][feature_2].isnull().values.any() == False) ):\n",
    "        return msm[r][feature_2].values[0]/1000\n",
    "    \n",
    "    elif((len(msm[r][feature_3]>0)) and (msm[r][feature_3].isnull().values.any() == False) ):\n",
    "        return msm[r][feature_3].values[0]/1000\n",
    "    \n",
    "    elif((len(msm[r][feature_4]>0) and msm[r][feature_4].isnull().values.any() == False) ):\n",
    "        return msm[r][feature_4].values[0]/1000\n",
    "    \n",
    "    else:\n",
    "        return row['Radiation(MSM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data(latitude,longitude,last_time):\n",
    "    # 抓取歷史資料\n",
    "    # 晴空輻射資料\n",
    "    sky_radiation = pd.read_csv('clear_sky_data/solar_汙水廠_ClearSkyRadiation.csv')\n",
    "    sky_radiation['TIME_TO_INTERVAL'] = pd.to_datetime(sky_radiation['TIME_TO_INTERVAL'])\n",
    "    mask = (sky_radiation['TIME_TO_INTERVAL'] >= last_time)\n",
    "    sky_radiation = sky_radiation[mask]\n",
    "    # 歷史輻射\n",
    "    cwb_rad_data = pd.read_csv('Observation_CWB/467490.csv')\n",
    "    cwb_rad_data = bulid_cwb_radiation(cwb_rad_data)\n",
    "    cwb_rad_data = cwb_rad_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\")\n",
    "    cwb_rad_data['TIME_TO_INTERVAL'] = pd.to_datetime(cwb_rad_data['TIME_TO_INTERVAL'])\n",
    "    mask = (cwb_rad_data['TIME_TO_INTERVAL'] >= last_time)\n",
    "    cwb_rad_data = cwb_rad_data[mask]\n",
    "    cwb_rad_data = cwb_rad_data[['TIME_TO_INTERVAL', 'Radiation']]\n",
    "    #合併晴空輻射資料和歷史輻射\n",
    "    data = pd.merge(sky_radiation,cwb_rad_data,on='TIME_TO_INTERVAL',how='outer')\n",
    "    # 歷史彰師大資料\n",
    "    NCUE = pd.read_csv('power_data/solar_汙水廠_history.csv')\n",
    "    NCUE['TIME_TO_INTERVAL'] = pd.to_datetime(NCUE['TIME_TO_INTERVAL'])\n",
    "    mask = (NCUE['TIME_TO_INTERVAL'] >= last_time)\n",
    "    NCUE = NCUE[mask]\n",
    "    #合併data和彰師大資料\n",
    "    data = pd.merge(data,NCUE,on='TIME_TO_INTERVAL',how='outer')\n",
    "    \n",
    "    #將data和中興大學輻射合併\n",
    "    data = merge_MSM(data,last_time)\n",
    "    \n",
    "#     old = pd.read_csv(f'./dataset/solar_汙水廠(history).csv')\n",
    "#     d = pd.concat([old, data], axis=0, ignore_index=True)\n",
    "#     d = d.drop_duplicates(subset=['TIME_TO_INTERVAL'], keep='last')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67fc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWB氣象局觀測資料整理\n",
    "def bulid_cwb_radiation(rad_raw):\n",
    "    rad_raw['GloblRad'] = rad_raw['GloblRad'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['Precp'] = rad_raw['Precp'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['WDGust'] = rad_raw['WDGust'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['WSGust'] = rad_raw['WSGust'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['WD'] = rad_raw['WD'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['WS'] = rad_raw['WS'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['RH'] = rad_raw['RH'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['Td dew point'] = rad_raw['Td dew point'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['Temperature'] = rad_raw['Temperature'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['SeaPres'] = rad_raw['SeaPres'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['Visb'] = rad_raw['Visb'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['UVI'] = rad_raw['UVI'].apply(lambda x:rename_str(x))\n",
    "    rad_raw['Cloud Amount'] = rad_raw['Cloud Amount'].apply(lambda x:rename_str(x))\n",
    "    #1kwh=3.6mj\n",
    "#     1w = 0.0036mj\n",
    "    rad_raw['GloblRad'].astype(float)\n",
    "    rad_raw['GloblRad'] = rad_raw['GloblRad']/3.6\n",
    "#     rad_raw['GloblRad'] = rad_raw['GloblRad']/0.0036\n",
    "    rad_raw['ObsTime'] = rad_raw['ObsTime']-1\n",
    "    rad_raw['TIME_TO_INTERVAL'] = rad_raw.apply(lambda raw:'{} {:02d}:00:00'.format(raw['date'], raw['ObsTime']), axis=1)\n",
    "    rad_raw = rad_raw[['TIME_TO_INTERVAL', 'date', 'ObsTime', 'GloblRad', \n",
    "                       'Precp', 'WDGust', 'WSGust', \n",
    "                       'WD', 'WS', 'RH', 'Td dew point', 'Temperature', \n",
    "                       'SeaPres', 'Visb', 'UVI', 'Cloud Amount']]\n",
    "    rad_raw = rad_raw.rename(columns={'ObsTime':'Hour', 'GloblRad':'Radiation', 'date':'Date'})\n",
    "    return rad_raw\n",
    "\n",
    "def rename_str(X):\n",
    "    if X=='/':\n",
    "        return np.nan\n",
    "    elif X=='X':\n",
    "        return np.nan\n",
    "    elif X=='...':\n",
    "        return np.nan\n",
    "    elif X=='T':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64580f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data merged into 3 hour units\n",
    "#依據每三小時來做數值平均\n",
    "def merge_data_to_3_hour(raw, add=[]):\n",
    "#     group_by_3h = ['TIME_TO_INTERVAL', 'Date', 'Hour' ,'dayOfYear', 'dayOfYear_t']+add\n",
    "    group_by_3h = ['TIME_TO_INTERVAL', 'Date', 'Hour']+add\n",
    "    data_3h = raw.copy()\n",
    "    data_3h['TIME_TO_INTERVAL'] = pd.to_datetime(data_3h['TIME_TO_INTERVAL'])\n",
    "    data_3h['Date'] = data_3h['TIME_TO_INTERVAL'].dt.date\n",
    "    data_3h['Hour'] = data_3h['TIME_TO_INTERVAL'].dt.hour\n",
    "    data_3h['TIME_TO_INTERVAL'] = pd.to_datetime(data_3h.apply(\n",
    "        lambda row: '{} {:02d}:00:00'.format(row['Date'], (row['Hour'])//3*3), axis=1))\n",
    "    data_3h['Hour'] = data_3h['TIME_TO_INTERVAL'].dt.hour\n",
    "    data_3h = data_3h.groupby(group_by_3h).mean().reset_index()\n",
    "    return data_3h\n",
    "# data merged into 1 hour units\n",
    "#依據每一小時來做數值平均\n",
    "def merge_data_to_1_hour(raw):\n",
    "    data_1h = raw.copy()\n",
    "    data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(data_1h['TIME_TO_INTERVAL'])\n",
    "    data_1h['Date'] = data_1h['TIME_TO_INTERVAL'].dt.date\n",
    "    data_1h['Hour'] = data_1h['TIME_TO_INTERVAL'].dt.hour\n",
    "    data_1h['Minute'] = data_1h['TIME_TO_INTERVAL'].dt.minute\n",
    "    data_1h['TIME_TO_INTERVAL_1h'] = pd.to_datetime(data_1h.apply(\n",
    "        lambda row: '{} {:02d}:{:02d}:00'.format(row['Date'], (row['Hour']), row['Minute']), axis=1))\n",
    "    data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(data_1h.apply(\n",
    "        lambda row: '{} {:02d}:{:02d}:00'.format(row['Date'], (row['Hour'])//3*3, row['Minute']), axis=1))\n",
    "    return data_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d14873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similar_day(start, data_1h, data_3h, plant_info, latitude, longitude, last_time):\n",
    "    sdv3 = {}\n",
    "    sdv3['CWB'] = int(plant_info['CWB'][0])\n",
    "    sdv3['IBM'] = int(plant_info['TWC'][0])\n",
    "    sdv3['OWM'] = int(plant_info['OWM'][0])\n",
    "    \n",
    "    # 氣象局預報\n",
    "    keys = ['CWB', 'IBM', 'OWM']\n",
    "    for key in keys:\n",
    "#         print(key)\n",
    "        if key == 'CWB':\n",
    "            weather_data = pd.read_csv('CWB.3H/save/CWB.3H.Merge.Multiple.csv')\n",
    "        elif key == 'IBM':\n",
    "            weather_data = pd.read_csv('WeatherChannel.1H/save/IBM.1H.Merge.Multiple(merge).csv')\n",
    "        else:\n",
    "            weather_data = pd.read_csv('OpenWeatherMap.3H/save/OWM.3H.Merge.Multiple(merge).csv')\n",
    "            weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(weather_data['TIME_TO_INTERVAL'])+datetime.timedelta(hours=1)\n",
    "            weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(weather_data['TIME_TO_INTERVAL'])\n",
    "\n",
    "        weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(weather_data['TIME_TO_INTERVAL'])\n",
    "        mask = (weather_data['TIME_TO_INTERVAL'] >= last_time)\n",
    "        weather_data = weather_data[mask]\n",
    "        #整理天氣預測類型\n",
    "        weather_data = build_weather_service_data(weather_data, longitude, latitude, key)\n",
    "        weather_data = weather_data[['TIME_TO_INTERVAL', 'TimeAhead', 'WeatherType']]\n",
    "    #     print(2)\n",
    "        weather_data_24h_ahead = weather_data[weather_data['TimeAhead'].eq(24)].reset_index(drop=True)  \n",
    "        weather_data = weather_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\", ignore_index=True)\n",
    "\n",
    "        data_3h['WeatherType'] = data_3h.apply(\n",
    "            lambda x: apply_weather_type(start, data_1h, key, x, weather_data), axis=1)\n",
    "        data_3h['WeatherType(pred)[1]'] = data_3h.apply(\n",
    "            lambda x: apply_weather_type(start, data_1h, key, x, weather_data_24h_ahead), axis=1)\n",
    "        data_3h['Alpha[1]'] = 1\n",
    "        data_3h[f'WeatherType({key})'] = data_3h['WeatherType']\n",
    "        data_3h[f'WeatherType(pred)({key})'] = data_3h['WeatherType(pred)[1]']\n",
    "    #     print(3)\n",
    "        data_1h['ClearSkyIndex'] = (data_1h['Radiation']/data_1h['ClearSkyRadiation'])\n",
    "        data_1h[f'Radiation(SDv3)({key})'] = data_1h.apply(lambda row: similar_day_radiation_v3(row, data_1h, data_3h,key, sdv3[key]), axis=1)\n",
    "        data_1h[f'Radiation(SDv3)({key})'] = data_1h.apply(lambda row: Radiation_SDv3_v3(row, data_1h,key), axis=1)\n",
    "        data_1h[f'Radiation(today)({key})'] = data_1h.apply(lambda row: similar_today_radiation_v3(row, data_1h, data_3h,key , sdv3[key]), axis=1)\n",
    "        data_1h[f'Radiation(today)({key})'] = data_1h.apply(lambda row: Radiation_today_v3(row, data_1h,key), axis=1)\n",
    "        \n",
    "        \n",
    "        # print(4)\n",
    "    data_3h = pd.concat([data_3h]*3)\n",
    "    data_3h = data_3h.sort_values(by=['TIME_TO_INTERVAL']).reset_index(drop=True)\n",
    "    for i in range(len(data_3h)):\n",
    "        data_3h.loc[i, 'TIME_TO_INTERVAL'] = data_3h.loc[i]['TIME_TO_INTERVAL'] + datetime.timedelta(hours=i % 3)\n",
    "\n",
    "    data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(data_1h.apply(\n",
    "        lambda row: '{} {:02d}:00:00'.format(row['Date'], (row['Hour'])), axis=1))\n",
    "\n",
    "    return data_1h, data_3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Radiation_SDv3_v3(row, data_1h,key):\n",
    "    if(row[f'Radiation(SDv3)({key})']==0 or row['ClearSkyRadiation']==0):\n",
    "        row[f'Radiation(SDv3)({key})']=0\n",
    "    else:\n",
    "        row[f'Radiation(SDv3)({key})']=row[f'Radiation(SDv3)({key})']*row['ClearSkyRadiation']\n",
    "    return row[f'Radiation(SDv3)({key})']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Radiation_today_v3(row, data_1h,key):\n",
    "    if(row[f'Radiation(today)({key})']==0 or row['ClearSkyRadiation']==0):\n",
    "        row[f'Radiation(today)({key})']=0\n",
    "    else:\n",
    "        row[f'Radiation(today)({key})']=row[f'Radiation(today)({key})']*row['ClearSkyRadiation']\n",
    "    return row[f'Radiation(today)({key})']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weather_service_data(raw, longitude, latitude, service='CWB'):\n",
    "    data = raw.copy()\n",
    "    \n",
    "    # read file and rename\n",
    "    if(service=='CWB'):\n",
    "        data['Location'] = data['LocationName'] + data['CityName']\n",
    "    elif(service=='IBM'):\n",
    "        data['Location'] = data['Name']\n",
    "    elif(service=='OWM'):\n",
    "        data['Location'] = data['Name']\n",
    "        \n",
    "    data = data.drop_duplicates(['TIME_TO_INTERVAL', 'Location', 'TimeAhead'], keep=\"last\")\n",
    "    \n",
    "    # select data by hour\n",
    "    data['TIME_TO_INTERVAL'] = pd.to_datetime(data['TIME_TO_INTERVAL'])\n",
    "    if(service=='OWM'):\n",
    "        data['TIME_TO_INTERVAL'] = data['TIME_TO_INTERVAL']+ datetime.timedelta(hours=1)\n",
    "    \n",
    "    data['Hour'] = pd.to_datetime(data['TIME_TO_INTERVAL']).dt.hour\n",
    "#     data = data[data['Hour'].isin(range(6, 17+1))]\n",
    "    \n",
    "    if(service=='CWB'):\n",
    "        data['WeatherType'] = data['WeatherType'].replace({\n",
    "            '午後短暫雷陣雨': '短暫陣雨或雷雨',\n",
    "            '有雨': '陣雨',\n",
    "            '短暫雨': '短暫陣雨',\n",
    "            '午後短暫陣雨': '短暫陣雨'})\n",
    "        data['WeatherType'] = data['WeatherType'].replace({\n",
    "            '短暫陣雨或雷雨': '陰',\n",
    "            '短暫陣雨': '陰',\n",
    "            '陣雨或雷雨': '陣雨'\n",
    "        })\n",
    "        \n",
    "        pass\n",
    "    elif(service=='OWM'):\n",
    "# #         能見度\n",
    "        data['WeatherType'] = data['WeatherType'].replace({\n",
    "            '晴，少雲':'晴',\n",
    "            '多雲':'晴',\n",
    "            '陰，多雲':'晴',\n",
    "            '小雨':'晴',\n",
    "        })\n",
    "        #rename\n",
    "        data['WeatherType'] = data['WeatherType'].replace({\n",
    "            '小雪':'陣雨',\n",
    "            '大雨':'陰',\n",
    "            '中雨':'多雲',\n",
    "        })\n",
    "\n",
    "        pass\n",
    "    \n",
    "    # find the recent forecast point, then get forecast data from recent point\n",
    "    locus = data.drop_duplicates(['Location'], keep=\"last\").reset_index(drop=True)\n",
    "    recent = get_recent_target(longitude, latitude, locus)\n",
    "    print(recent)\n",
    "    data = data[data['Location'].eq(recent)].reset_index(drop=True)\n",
    "    \n",
    "    # info output\n",
    "#     print('服務預報點：', recent)\n",
    "#     print(data.drop_duplicates(['WeatherType'], keep=\"last\")['WeatherType'])\n",
    "    data = data.sort_values(by=['TIME_TO_INTERVAL', 'TimeAhead'])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "# calculate distance based on latitude and longitude\n",
    "def geodistance(lon_a, lat_a, lon_b, lat_b):\n",
    "    lon_a, lat_a, lon_b, lat_b = map(radians, [lon_a, lat_a, lon_b, lat_b])\n",
    "    dlon = lon_b - lon_a\n",
    "    dlat = lat_b - lat_a\n",
    "    a = sin(dlat/2)**2 + cos(lat_a) * cos(lat_b) * sin(dlon/2)**2\n",
    "    dis = 2*asin(sqrt(a))*6371*1000\n",
    "    return dis\n",
    "def get_recent_target(longitude, latitude, locus, column='Location'):\n",
    "    # initialization\n",
    "    # recent_point: 表示距離輸入 plant 最近的 \"預報點\"，最終會被回傳\n",
    "    # shortest_dist: 表示表示距離輸入 station 最近 \"預報點\" 的距離，初始值設很大是為了避免一直寫入\n",
    "    recent_point = 'Not Found.'\n",
    "    shortest_dist = 1000*1000\n",
    "\n",
    "    # go through the search list\n",
    "    for i in range(len(locus)):\n",
    "        current = locus.loc[i]\n",
    "        dist = geodistance(\n",
    "            longitude, latitude, \n",
    "            float(current['Longitude']), float(current['Latitude']))\n",
    "\n",
    "        # if the current distance is shorter than the historical shortest distance\n",
    "        # then use current point replace recent point\n",
    "        if(dist < shortest_dist):\n",
    "            shortest_dist = dist\n",
    "            recent_point = current[column]\n",
    "    # end of search, return\n",
    "    return recent_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply weather type from forecast data(cwb, weather.com, open weather map).\n",
    "def apply_weather_type(start, data_1h, key, row, weather_forecast, default='晴'):\n",
    "    ''' apply weather type from forecast data(cwb, weather.com, open weather map).\n",
    "    '''\n",
    "    if pd.to_datetime(row['TIME_TO_INTERVAL']) >= start:\n",
    "        \n",
    "        mask = weather_forecast['TIME_TO_INTERVAL'].eq(row['TIME_TO_INTERVAL'])\n",
    "        if(mask.any()):\n",
    "#             print(f\">= start: {start}, {row['TIME_TO_INTERVAL']}, {weather_forecast[mask]['WeatherType'].values[0]}\")\n",
    "            return weather_forecast[mask]['WeatherType'].values[0]\n",
    "        else:\n",
    "#             print(f'Not Found.>= start: {start}', row['TIME_TO_INTERVAL'])\n",
    "              #若不存在取代為nan\n",
    "    #         return np.nan\n",
    "            return '晴'\n",
    "    else:\n",
    "        history_data = pd.read_csv('./dataset/solar_汙水廠(history).csv')\n",
    "        mask = history_data['TIME_TO_INTERVAL'].eq(pd.to_datetime(row['TIME_TO_INTERVAL']))\n",
    "        if(mask.any()):\n",
    "#             print(f\"< start: {start}, {row['TIME_TO_INTERVAL']}, {data_1h[mask][f'WeatherType({key})'].values[0]}\")\n",
    "            return history_data[mask][f'WeatherType({key})'].values[0]\n",
    "        else:\n",
    "#            print(f'Not Found. < start: {start}', row['TIME_TO_INTERVAL'])\n",
    "              #若不存在取代為nan\n",
    "    #         return np.nan\n",
    "            return '晴'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec232bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similar_day_radiation_v3(row, raw_1h, raw_3h, limit=10):\n",
    "#     # init\n",
    "#     data_1h = raw_1h.copy()\n",
    "#     data_3h = raw_3h.copy()\n",
    "\n",
    "#     # 篩選出這筆小時單位資料，在三小時單位的位置(至多1筆)\n",
    "#     mask = data_3h['TIME_TO_INTERVAL'].eq(row['TIME_TO_INTERVAL'])\n",
    "# #     print(row['TIME_TO_INTERVAL'])\n",
    "# #     print(data_3h[mask])\n",
    "#     row_3h = data_3h[mask].iloc[0]\n",
    "\n",
    "#     # 篩選出所有三小時單位資料當中，和目前資料相同時間段(3小時單位)的資料\n",
    "#     mask = data_3h['Hour'].eq(row_3h['Hour'])\n",
    "#     date_in_same_zone = data_3h[mask].reset_index(inplace=False, drop=True)\n",
    "\n",
    "#     # 篩選出三小時資料當中，早於當前時間的資料\n",
    "#     mask = (date_in_same_zone['TIME_TO_INTERVAL']<row_3h['TIME_TO_INTERVAL'])\n",
    "#     date_in_same_zone = date_in_same_zone[mask]\n",
    "\n",
    "#     # 取得相同時間帶內，同樣天氣類型的資料\n",
    "#     target_weather = row_3h['WeatherType(pred)[1]']\n",
    "#     date_with_same_weather = date_in_same_zone[date_in_same_zone['WeatherType'].eq(target_weather)]\n",
    "#     date_with_same_weather = date_with_same_weather.reset_index(inplace=False, drop=True)\n",
    "#     date_with_same_weather = date_with_same_weather['TIME_TO_INTERVAL'].tolist()\n",
    "\n",
    "#     # 找到相似日的日期後，切換回 1 小時單位取樣\n",
    "#     mask1 = data_1h['TIME_TO_INTERVAL'].isin(date_with_same_weather)\n",
    "#     mask2 = data_1h['Hour'].eq(row['Hour'])\n",
    "#     available_data = data_1h[mask1 & mask2]\n",
    "\n",
    "#     # 反轉資料時間順序，以利取得相對目標日而言較近的資料\n",
    "#     # 移除有缺值的日子，不要被計入\n",
    "#     available_data = available_data.iloc[::-1].reset_index(inplace=False, drop=True)\n",
    "# #     available_data = available_data[~available_data['Radiation'].isna()]\n",
    "#     available_data = available_data[~available_data['Radiation'].isna()]\n",
    "\n",
    "#     # 取用最佳化的相似日數量，最佳化的數字必須由使用者提供\n",
    "#     available_data = available_data[:limit]\n",
    "\n",
    "#     if(len(available_data)>0):\n",
    "#         available_data = available_data['ClearSkyIndex'].mean()\n",
    "#         return available_data\n",
    "#     else:\n",
    "#         return np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_day_radiation_v3(row, raw_1h, raw_3h,key, limit=10):\n",
    "    # init\n",
    "    data_1h = raw_1h.copy()\n",
    "    data_3h = raw_3h.copy()\n",
    "    \n",
    "    history_data = pd.read_csv('./dataset/solar_汙水廠(history).csv')\n",
    "    history_data['TIME_TO_INTERVAL'] = pd.to_datetime(history_data['TIME_TO_INTERVAL'])\n",
    "    history_data['Hour'] = history_data['TIME_TO_INTERVAL'].dt.hour\n",
    "    history_data['Date'] = history_data['TIME_TO_INTERVAL'].dt.date\n",
    "    history_data['ClearSkyIndex'] = (history_data['Radiation']/history_data['ClearSkyRadiation'])\n",
    "    # 篩選出這筆小時單位資料，在三小時單位的位置(至多1筆)\n",
    "    mask = data_3h['Hour'].eq((row['Hour'])//3*3)\n",
    "#     print(row['TIME_TO_INTERVAL'])\n",
    "#     print(data_3h[mask])\n",
    "    row_3h = data_3h[mask].iloc[0]\n",
    "    # 篩選出所有三小時單位資料當中，和目前資料相同時間段(3小時單位)的資料\n",
    "    mask = history_data['Hour'].eq(row_3h['Hour'])\n",
    "    date_in_same_zone = history_data[mask].reset_index(inplace=False, drop=True)\n",
    "\n",
    "    # 篩選出三小時資料當中，早於當前時間的資料\n",
    "    mask = (date_in_same_zone['TIME_TO_INTERVAL']<row_3h['TIME_TO_INTERVAL'])\n",
    "    date_in_same_zone = date_in_same_zone[mask]\n",
    "    \n",
    "    # 取得相同時間帶內，同樣天氣類型的資料\n",
    "    target_weather = row_3h['WeatherType(pred)[1]']\n",
    "    date_with_same_weather = date_in_same_zone[date_in_same_zone[f'WeatherType({key})'].eq(target_weather)]\n",
    "    date_with_same_weather = date_with_same_weather.reset_index(inplace=False, drop=True)\n",
    "#     date_with_same_weather = date_with_same_weather['TIME_TO_INTERVAL'].tolist()\n",
    "    # 找到相似日的日期後，切換回 1 小時單位取樣\n",
    "    #print(date_with_same_weather,'-----------------------------------------')\n",
    "    mask1 = history_data['Date'].isin(date_with_same_weather['Date'])\n",
    "    #print(date_with_same_weather)\n",
    "    mask2 = history_data['Hour'].eq(row['Hour'])\n",
    "    available_data = history_data[(mask1 & mask2)]\n",
    "    #print(available_data)\n",
    "    # 反轉資料時間順序，以利取得相對目標日而言較近的資料\n",
    "    # 移除有缺值的日子，不要被計入\n",
    "    available_data = available_data.iloc[::-1].reset_index(inplace=False, drop=True)\n",
    "#     available_data = available_data[~available_data['Radiation'].isna()]\n",
    "    available_data = available_data[~available_data['Radiation'].isna()]\n",
    "\n",
    "    # 取用最佳化的相似日數量，最佳化的數字必須由使用者提供\n",
    "    available_data = available_data[:limit]\n",
    "\n",
    "    if(len(available_data)>0):\n",
    "        available_data = available_data['ClearSkyIndex'].mean()\n",
    "        return available_data\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_today_radiation_v3(row, raw_1h, raw_3h,key, limit=10):\n",
    "    # init\n",
    "    data_1h = raw_1h.copy()\n",
    "    data_3h = raw_3h.copy()\n",
    "    \n",
    "    history_data = pd.read_csv('./dataset/solar_汙水廠(history).csv')\n",
    "    history_data['TIME_TO_INTERVAL'] = pd.to_datetime(history_data['TIME_TO_INTERVAL'])\n",
    "    history_data['Hour'] = history_data['TIME_TO_INTERVAL'].dt.hour\n",
    "    history_data['Date'] = history_data['TIME_TO_INTERVAL'].dt.date\n",
    "    history_data['ClearSkyIndex'] = (history_data['Radiation']/history_data['ClearSkyRadiation'])\n",
    "    \n",
    "    # 篩選出這筆小時單位資料，在三小時單位的位置(至多1筆)\n",
    "    mask = data_3h['Hour'].eq((row['Hour'])//3*3)\n",
    "#     print(row['TIME_TO_INTERVAL'])\n",
    "#     print(data_3h[mask])\n",
    "    row_3h = data_3h[mask].iloc[0]\n",
    "\n",
    "    # 篩選出所有三小時單位資料當中，和目前資料相同時間段(3小時單位)的資料\n",
    "    mask = history_data['Hour'].eq(row_3h['Hour'])\n",
    "    date_in_same_zone = history_data[mask].reset_index(inplace=False, drop=True)\n",
    "    # 篩選出三小時資料當中，早於當前時間的資料\n",
    "    mask = (date_in_same_zone['TIME_TO_INTERVAL']<row_3h['TIME_TO_INTERVAL'])\n",
    "    date_in_same_zone = date_in_same_zone[mask]\n",
    "\n",
    "    # 取得相同時間帶內，同樣天氣類型的資料\n",
    "    target_weather = row_3h['WeatherType(pred)[1]']\n",
    "    date_with_same_weather = date_in_same_zone[date_in_same_zone[f'WeatherType({key})'].eq(target_weather)]\n",
    "    date_with_same_weather = date_with_same_weather.reset_index(inplace=False, drop=True)\n",
    "#     date_with_same_weather = date_with_same_weather['TIME_TO_INTERVAL'].tolist()\n",
    "\n",
    "    # 找到相似日的日期後，切換回 1 小時單位取樣\n",
    "    mask1 = history_data['Date'].isin(date_with_same_weather['Date'])\n",
    "    mask2 = history_data['Hour'].eq(row['Hour'])\n",
    "    available_data = history_data[mask1 & mask2]\n",
    "\n",
    "    # 反轉資料時間順序，以利取得相對目標日而言較近的資料\n",
    "    # 移除有缺值的日子，不要被計入\n",
    "    available_data = available_data.iloc[::-1].reset_index(inplace=False, drop=True)\n",
    "#     available_data = available_data[~available_data['Radiation'].isna()]\n",
    "    available_data = available_data[~available_data['Radiation'].isna()]\n",
    "\n",
    "    # 取用最佳化的相似日數量，最佳化的數字必須由使用者提供\n",
    "    available_data = available_data[:limit]\n",
    "#     print(available_data)\n",
    "    if(len(available_data)>0):\n",
    "        available_data = available_data['ClearSkyIndex'].mean()\n",
    "        return available_data\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce025297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merge(start, data_1h, data_3h):\n",
    "    data_1h = data_1h[['TIME_TO_INTERVAL','Power',\n",
    "                       'Radiation', 'ClearSkyRadiation',\n",
    "                       'Radiation(SDv3)(CWB)','Radiation(SDv3)(IBM)',\n",
    "                       'Radiation(SDv3)(OWM)','Radiation(MSM)',\n",
    "                       'Radiation(today)(CWB)','Radiation(today)(IBM)',\n",
    "                       'Radiation(today)(OWM)'\n",
    "                      ]]\n",
    "    data_3h = data_3h[['TIME_TO_INTERVAL', \n",
    "                       'WeatherType(CWB)', 'WeatherType(pred)(CWB)',\n",
    "                       'WeatherType(IBM)', 'WeatherType(pred)(IBM)',\n",
    "                       'WeatherType(OWM)', 'WeatherType(pred)(OWM)',\n",
    "                      ]]\n",
    "\n",
    "    data = pd.merge(data_1h, data_3h, on=['TIME_TO_INTERVAL'], how='outer').sort_values(by='TIME_TO_INTERVAL').reset_index(drop=True)\n",
    "    data = data.drop_duplicates(subset=['TIME_TO_INTERVAL'], keep=\"last\")\n",
    "    data['TIME_TO_INTERVAL'] = pd.to_datetime(data['TIME_TO_INTERVAL'])\n",
    "    data = data.sort_values(by='TIME_TO_INTERVAL')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b849c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather(data,last_time):\n",
    "    #讀取資料\n",
    "    CWB_weather_data = pd.read_csv('./CWB.3H/save/CWB.3H.Merge.Multiple.csv')\n",
    "    CWB_weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(CWB_weather_data['TIME_TO_INTERVAL'])\n",
    "    mask = (CWB_weather_data['TIME_TO_INTERVAL'] >= last_time)\n",
    "    CWB_weather_data = CWB_weather_data[mask]\n",
    "    \n",
    "    IBM_weather_data = pd.read_csv('./WeatherChannel.1H/save/IBM.1H.Merge.Multiple(merge).csv')\n",
    "    IBM_weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(IBM_weather_data['TIME_TO_INTERVAL'])\n",
    "    mask = (IBM_weather_data['TIME_TO_INTERVAL'] >= last_time)\n",
    "    IBM_weather_data = IBM_weather_data[mask]\n",
    "    \n",
    "    OWM_weather_data = pd.read_csv('./OpenWeatherMap.3H/save/OWM.3H.Merge.Multiple(merge).csv')\n",
    "    OWM_weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(OWM_weather_data['TIME_TO_INTERVAL'])\n",
    "    mask = (OWM_weather_data['TIME_TO_INTERVAL'] >= last_time)\n",
    "    OWM_weather_data = OWM_weather_data[mask]\n",
    "\n",
    "    #抓取最近距離\n",
    "    CWB_weather_data = get_recent(CWB_weather_data, longitude, latitude, 'CWB')\n",
    "    IBM_weather_data = get_recent(IBM_weather_data, longitude, latitude, 'IBM')\n",
    "    OWM_weather_data = get_recent(OWM_weather_data, longitude, latitude, 'OWM')\n",
    "    #抓出想要欄位，並重新命名\n",
    "    CWB_weather_data = CWB_weather_data[['TIME_TO_INTERVAL', 'ApparentTemperature(pred)', 'Temperature(pred)','RelativeHumidity(pred)']]\n",
    "    CWB_weather_data = CWB_weather_data.rename(columns={'ApparentTemperature(pred)':'ApparentTemperature(pred)[CWB]',\n",
    "                                                        'Temperature(pred)':'Temperature(pred)[CWB]',\n",
    "                                                        'RelativeHumidity(pred)':'RelativeHumidity(pred)[CWB]'})\n",
    "    IBM_weather_data = IBM_weather_data[['TIME_TO_INTERVAL', 'FeelsLikeTemperature(pred)', 'Temperature(pred)','RelativeHumidity(pred)']]\n",
    "    IBM_weather_data = IBM_weather_data.rename(columns={'FeelsLikeTemperature(pred)':'FeelsLikeTemperature(pred)[IBM]',\n",
    "                                                        'Temperature(pred)':'Temperature(pred)[IBM]',\n",
    "                                                        'RelativeHumidity(pred)':'RelativeHumidity(pred)[IBM]'})\n",
    "    OWM_weather_data = OWM_weather_data[['TIME_TO_INTERVAL', 'FeelsLikeTemperature(pred)', 'Temperature(pred)','RelativeHumidity(pred)']]\n",
    "    OWM_weather_data = OWM_weather_data.rename(columns={'FeelsLikeTemperature(pred)':'FeelsLikeTemperature(pred)[OWM]',\n",
    "                                                        'Temperature(pred)':'Temperature(pred)[OWM]',\n",
    "                                                        'RelativeHumidity(pred)':'RelativeHumidity(pred)[OWM]'})\n",
    "    OWM_weather_data['TIME_TO_INTERVAL'] = pd.to_datetime(OWM_weather_data['TIME_TO_INTERVAL'])+datetime.timedelta(hours=1)\n",
    "    #刪除重複值(取最後一筆，表示預測資料)\n",
    "    CWB_weather_data = CWB_weather_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\", ignore_index=True)\n",
    "    IBM_weather_data = IBM_weather_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\", ignore_index=True)\n",
    "    OWM_weather_data = OWM_weather_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\", ignore_index=True)\n",
    "    \n",
    "    #因資料是每三小時一筆，改成每小時一筆\n",
    "    CWB_weather_data_1h = pd.concat([CWB_weather_data]*3)\n",
    "    CWB_weather_data_1h = CWB_weather_data_1h.sort_values(by=['TIME_TO_INTERVAL']).reset_index(drop=True)\n",
    "    IBM_weather_data_1h = IBM_weather_data\n",
    "    IBM_weather_data_1h = IBM_weather_data_1h.sort_values(by=['TIME_TO_INTERVAL']).reset_index(drop=True)\n",
    "    OWM_weather_data_1h = pd.concat([OWM_weather_data]*3)\n",
    "    OWM_weather_data_1h = OWM_weather_data_1h.sort_values(by=['TIME_TO_INTERVAL']).reset_index(drop=True)\n",
    "\n",
    "    CWB_weather_data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(CWB_weather_data_1h['TIME_TO_INTERVAL'])\n",
    "    for i in range(len(CWB_weather_data_1h)):\n",
    "        CWB_weather_data_1h.loc[i, 'TIME_TO_INTERVAL'] = CWB_weather_data_1h.loc[i]['TIME_TO_INTERVAL'] + datetime.timedelta(hours=i % 3)\n",
    "\n",
    "    IBM_weather_data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(IBM_weather_data_1h['TIME_TO_INTERVAL'])\n",
    "    for i in range(len(IBM_weather_data_1h)):\n",
    "        IBM_weather_data_1h.loc[i, 'TIME_TO_INTERVAL'] = IBM_weather_data_1h.loc[i]['TIME_TO_INTERVAL'] + datetime.timedelta(hours=i % 3)\n",
    "\n",
    "    OWM_weather_data_1h['TIME_TO_INTERVAL'] = pd.to_datetime(OWM_weather_data_1h['TIME_TO_INTERVAL'])\n",
    "    for i in range(len(OWM_weather_data_1h)):\n",
    "        OWM_weather_data_1h.loc[i, 'TIME_TO_INTERVAL'] = OWM_weather_data_1h.loc[i]['TIME_TO_INTERVAL'] + datetime.timedelta(hours=i % 3)\n",
    "\n",
    "    merge_weather = pd.merge(CWB_weather_data_1h, IBM_weather_data_1h, on=['TIME_TO_INTERVAL'], how='outer').sort_values(by='TIME_TO_INTERVAL').reset_index(drop=True)\n",
    "    merge_weather = pd.merge(merge_weather, OWM_weather_data_1h, on=['TIME_TO_INTERVAL'], how='outer').sort_values(by='TIME_TO_INTERVAL').reset_index(drop=True)\n",
    "    merge_weather\n",
    "\n",
    "    data = pd.merge(data, merge_weather, on=['TIME_TO_INTERVAL'], how='outer').sort_values(by='TIME_TO_INTERVAL').reset_index(drop=True)\n",
    "#     print(data,'------------------------------------')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent(raw, longitude, latitude, service='CWB'):\n",
    "    data = raw.copy()\n",
    "    # read file and rename\n",
    "    if(service=='CWB'):\n",
    "        data['Location'] = data['LocationName'] + data['CityName']\n",
    "    elif(service=='IBM'):\n",
    "        data['Location'] = data['Name']\n",
    "    elif(service=='OWM'):\n",
    "        data['Location'] = data['Name']\n",
    "        \n",
    "    data = data.drop_duplicates(['TIME_TO_INTERVAL', 'Location', 'TimeAhead'], keep=\"last\")\n",
    "    \n",
    "    # find the recent forecast point, then get forecast data from recent point\n",
    "    locus = data.drop_duplicates(['Location'], keep=\"last\").reset_index(drop=True)\n",
    "    recent = get_recent_target(longitude, latitude, locus)\n",
    "#     print(recent)\n",
    "    data = data[data['Location'].eq(recent)].reset_index(drop=True)\n",
    "    \n",
    "    # info output\n",
    "#     print('服務預報點：', recent)\n",
    "    data = data.sort_values(by=['TIME_TO_INTERVAL', 'TimeAhead'])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b90be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant_info = pd.read_csv('Plant_Info_Baoshan.csv')\n",
    "# plant_info = plant_info.loc[1:1].reset_index(drop=True)\n",
    "# # 案場資料\n",
    "# latitude = plant_info['Latitude'][0]\n",
    "# longitude = plant_info['Longitude'][0]\n",
    "\n",
    "# #天氣資料打包\n",
    "# day = datetime.datetime.today()\n",
    "# day = pd.to_datetime(day, format='%Y%m%d')\n",
    "# start = pd.to_datetime(str(day.year)+'-'+str(day.month)+'-'+str(day.day))\n",
    "# # weather_data(start)\n",
    "# #抓取歷史資料最後時間\n",
    "# history = pd.read_csv('./dataset/solar_汙水廠(history).csv')\n",
    "# last_time = history[-1:]['TIME_TO_INTERVAL'].values[0]\n",
    "# last_time = pd.to_datetime(last_time)\n",
    "# if(start<=last_time):\n",
    "#     last_time = start\n",
    "# else:\n",
    "#     last_time = last_time\n",
    "# #抓取彰師大發電量歷史資料、觀測站歷史資料、晴空輻射歷史資料\n",
    "# merge_data = all_data(latitude,longitude,last_time)\n",
    "# print(merge_data)\n",
    "# merge_data['TIME_TO_INTERVAL'] = pd.to_datetime(merge_data['TIME_TO_INTERVAL'])\n",
    "# merge_data['Hour'] = merge_data['TIME_TO_INTERVAL'].dt.hour\n",
    "# #分成三小時版和一小時版\n",
    "# data_3h = merge_data_to_3_hour(merge_data)\n",
    "# data_1h = merge_data_to_1_hour(merge_data) \n",
    "# #print(data_1h)\n",
    "# #依據天氣類型去計算相似日的輻射值\n",
    "# data_1h, data_3h = calculate_similar_day(start, data_1h, data_3h, plant_info, latitude, longitude, last_time)\n",
    "# #print(data_1h)\n",
    "# #將預測的相似輻射值和真實的歷史資料合併data\n",
    "# data = data_merge(start, data_1h, data_3h)\n",
    "# #將data和我們所需的天氣預測欄位合併\n",
    "# data  = Weather(data, last_time)\n",
    "# #將data和中興大學輻射合併\n",
    "# total_data = merge_MSM(data,last_time)\n",
    "# old = pd.read_csv(f'./dataset/solar_汙水廠(history).csv')\n",
    "# d = pd.concat([old, total_data], axis=0, ignore_index=True)\n",
    "# d = d.drop_duplicates(subset=['TIME_TO_INTERVAL'], keep='last')\n",
    "# d.to_csv(f'./dataset/solar_汙水廠(history).csv', index=None)\n",
    "# total_data.to_csv('./dataset/solar_汙水廠(new).csv', index=None)\n",
    "# print('merge_okok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04b9b5",
   "metadata": {},
   "source": [
    "# 每小時又兩分執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257aae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plant_info = pd.read_csv('Plant_Info_Baoshan.csv')\n",
    "plant_info = plant_info.loc[1:1].reset_index(drop=True)\n",
    "# 案場資料\n",
    "latitude = plant_info['Latitude'][0]\n",
    "longitude = plant_info['Longitude'][0]\n",
    "while(True):\n",
    "    localtime = time.localtime()\n",
    "    result = time.strftime(\"%M:%S\", localtime)\n",
    "    #0~5分執行的話會報錯\n",
    "    if(result<='05:00'):\n",
    "        start_time = time.time()\n",
    "        last_time = '2021-04-01'\n",
    "        #天氣資料打包\n",
    "        day = datetime.datetime.today()\n",
    "        day = pd.to_datetime(day, format='%Y%m%d')\n",
    "        start = pd.to_datetime(str(day.year)+'-'+str(day.month)+'-'+str(day.day))-datetime.timedelta(days=1)\n",
    "        #整合天氣預報資料\n",
    "        weather_data(start)\n",
    "        #抓取彰師大發電量歷史資料、觀測站歷史資料、晴空輻射歷史資料\n",
    "        merge_data = all_data(latitude,longitude,start)\n",
    "#         print(merge_data)\n",
    "        merge_data['TIME_TO_INTERVAL'] = pd.to_datetime(merge_data['TIME_TO_INTERVAL'])\n",
    "        merge_data['Hour'] = merge_data['TIME_TO_INTERVAL'].dt.hour\n",
    "        #分成三小時版和一小時版\n",
    "        data_3h = merge_data_to_3_hour(merge_data)\n",
    "        data_1h = merge_data_to_1_hour(merge_data) \n",
    "        #print(data_1h)\n",
    "        #依據天氣類型去計算相似日的輻射值\n",
    "        data_1h, data_3h = calculate_similar_day(start, data_1h, data_3h, plant_info, latitude, longitude, last_time)\n",
    "        #print(data_1h)\n",
    "        #將預測的相似輻射值和真實的歷史資料合併data\n",
    "        data = data_merge(start, data_1h, data_3h)\n",
    "        #將data和我們所需的天氣預測欄位合併\n",
    "        total_data  = Weather(data, start)\n",
    "#         print(data)\n",
    "        old = pd.read_csv(f'./dataset/solar_汙水廠(history).csv')\n",
    "        d = pd.concat([old, total_data], axis=0, ignore_index=True)\n",
    "        d['TIME_TO_INTERVAL'] = pd.to_datetime(d['TIME_TO_INTERVAL'])\n",
    "        d = d.drop_duplicates(subset=['TIME_TO_INTERVAL'], keep='last')\n",
    "        d = d.sort_values(by='TIME_TO_INTERVAL')\n",
    "        d.to_csv(f'./dataset/solar_汙水廠(history).csv', index=None)\n",
    "        total_data.to_csv('./dataset/solar_汙水廠(new).csv', index=None)\n",
    "        print('merge_okok')\n",
    "        end_time = time.time()\n",
    "        finish = end_time - start_time\n",
    "        print(finish)\n",
    "        time.sleep(3600-finish)\n",
    "    else:\n",
    "        m,s = result.strip().split(\":\")\n",
    "        start_time = int(m)*60+int(s)\n",
    "        time.sleep(3720-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0d4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_csv(f'./dataset/solar_汙水廠(history).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "old[14500:14540]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
