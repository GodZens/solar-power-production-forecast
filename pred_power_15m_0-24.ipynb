{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddb457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from influxdb import InfluxDBClient\n",
    "from tqdm import tqdm\n",
    "databasename = ['MG1']\n",
    "client = InfluxDBClient('120.107.146.56', 8086, 'ncue01', 'Q!A@Z#WSX', 'MG1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1f741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "#資料庫\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn_rvm import EMRVC\n",
    "from sklearn_rvm import EMRVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "#載入模型\n",
    "import joblib\n",
    "#繪圖工具\n",
    "import matplotlib.dates as md\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be511df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 在線使用設置##############\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.express as px\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365c9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_old_power():\n",
    "#     path=\"C:\\\\Users\\\\IDSL\\\\Desktop\\\\G.Z\\\\太陽能\\\\太陽能發電\\\\天氣資料爬蟲與合併\\\\power_data\\\\MG1_PV\"\n",
    "#     filenames = os.listdir(path)\n",
    "#     old_power = pd.DataFrame()\n",
    "#     for excel in tqdm(filenames):\n",
    "#         power=pd.read_csv(os.path.join(path,excel))\n",
    "#         old_power=pd.concat([old_power,power],axis=0, ignore_index=True)\n",
    "#     return old_power\n",
    "# old_power = get_old_power()\n",
    "# old_power = old_power.rename(columns={'time':'TIME_TO_INTERVAL'})\n",
    "# old_power = old_power.sort_values(by=['TIME_TO_INTERVAL'])\n",
    "# old_power = bulid_15minute_data(old_power)\n",
    "# old_power.to_csv('power_data/original/save/merge_power_data(old_15min).csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd91bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取資料庫全部資料\n",
    "def get_power(date):\n",
    "    tablename = 'MG1_PV'\n",
    "    sql = f\"SELECT * FROM {tablename} where Time >= '{date}' - 8h\"#中原標準時間，為中華民國現行採用的標準時間，比世界協調時間快八個小時\n",
    "    print(sql)\n",
    "    result = client.query(sql) \n",
    "    #result = client.query(f'SELECT * FROM {tablename}') \n",
    "    data =  list(result.get_points())\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.rename(columns={'Time':'TIME_TO_INTERVAL'})\n",
    "    data = bulid_15minute_data(data)\n",
    "    #data_2.to_csv('power_data/original/save/merge_power_data(15min).csv',index=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82cdf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#轉為小時單位\n",
    "def bulid_15minute_data(data_raw):\n",
    "    data_raw['TIME_TO_INTERVAL'] = pd.to_datetime(data_raw['TIME_TO_INTERVAL'])\n",
    "    data_raw_2 = data_raw.groupby(pd.Grouper(key=\"TIME_TO_INTERVAL\",freq='15min', origin='start')).mean().reset_index()\n",
    "    return data_raw_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194fb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day = datetime.datetime.today()\n",
    "# day = pd.to_datetime(day, format='%Y%m%d')\n",
    "# day = pd.to_datetime(str(day.year)+'-'+str(day.month)+'-'+str(day.day))\n",
    "\n",
    "# data = get_power(day)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac2184",
   "metadata": {},
   "source": [
    "# 正式開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c93475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,target_day):\n",
    "    power_list=['pre_Power_15','pre_Power_30','pre_Power_45']\n",
    "    Radiation_list=['pre_Radiation_15','Radiation_0','next_Radiation_15']\n",
    "    data_merge = data.copy()\n",
    "    row = target_day.copy()\n",
    "    #建立三個表\n",
    "    data_power = pd.DataFrame()\n",
    "    data_Radiation = pd.DataFrame()\n",
    "    data_2 = pd.DataFrame()  \n",
    "    #抓取該筆資料的日期和時間\n",
    "    data_power = data_merge[data_merge['date'].isin(row['date'])]\n",
    "    row_time = pd.to_datetime(row['TIME_TO_INTERVAL'].values[0])\n",
    "    #獲得該時間的前15,30,45分鐘\n",
    "    pre_time = [row_time-datetime.timedelta(minutes=15),\n",
    "                row_time-datetime.timedelta(minutes=30),\n",
    "                row_time-datetime.timedelta(minutes=45)]\n",
    "    for i in range(len(pre_time)):\n",
    "        pre_time[i] = pre_time[i].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "       \n",
    "    #獲得該時間的前15,現在,未來15分鐘\n",
    "    pre_Radiation = [row_time-datetime.timedelta(minutes=15),\n",
    "                    row_time,\n",
    "                    row_time+datetime.timedelta(minutes=15)]\n",
    "    for i in range(len(pre_Radiation)):\n",
    "        pre_Radiation[i] = pre_Radiation[i].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    #獲得該日期的當天和明天全部資料\n",
    "    row_date = pd.to_datetime(row['date'].values[0])\n",
    "    next_date = [row_date,\n",
    "                 row_date+datetime.timedelta(days=1)]   \n",
    "    for i in range(len(next_date)):\n",
    "        next_date[i] = next_date[i].strftime(\"%Y-%m-%d\")\n",
    "    data_merge['date'] = data_merge['date'].apply(lambda x: x.strftime('%Y-%m-%d'))     \n",
    "    data_Radiation = data_merge[data_merge['date'].isin(next_date)]\n",
    "\n",
    "    #依據pre_time和pre_Radiation的時間獲得該時段的power和Radiation\n",
    "    #兩天都有資料的話，會有6筆，但只取前三筆(當日)\n",
    "    #因如為24:00,則需要抓取當天和明天資料,並只取當天\n",
    "    for h in range(0,3): \n",
    "\n",
    "        data_power_2 = data_power[data_power['TIME_TO_INTERVAL'].isin([pre_time[h]])].reset_index(drop=True)  \n",
    "        data_Radiation_2 = data_Radiation[data_Radiation['TIME_TO_INTERVAL'].isin([pre_Radiation[h]])].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "        if(len(data_power_2)==0):\n",
    "            data_2[power_list[h]] = [0]\n",
    "#             print('---------------',data_2[power_list[h]])\n",
    "        else:\n",
    "            data_2[power_list[h]] = data_power_2['Power']\n",
    "            \n",
    "        if(len(data_Radiation_2)==0):\n",
    "            data_2[Radiation_list[h]] = [0]\n",
    "        else:\n",
    "            data_2[Radiation_list[h]] = data_Radiation_2['Radiation(today)(CWB)']\n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f08921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, model_name):\n",
    "    #模型訓練\n",
    "    if model_name == 'xgb':\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                        learning_rate=0.01, \n",
    "                        max_depth=1,\n",
    "                        colsample_bytree=0.1,\n",
    "                        reg_lambda=0.01,\n",
    "                        seed=1,\n",
    "                        subsample=0.1,\n",
    "                        min_child_weight=1,\n",
    "                        n_estimators=4000).fit(train_x, train_y)\n",
    "    elif model_name == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "               boosting_type='gbdt',\n",
    "                     verbose = 0,\n",
    "                     learning_rate = 0.01,\n",
    "                     num_leaves = 35,\n",
    "                     feature_fraction=0.8,\n",
    "                     bagging_fraction= 0.9,\n",
    "                     bagging_freq= 8,\n",
    "                     lambda_l1= 0.6,\n",
    "                     lambda_l2= 0).fit(train_x, train_y)\n",
    "    elif model_name == 'svr':\n",
    "        model = SVR(C=1, kernel=\"rbf\", gamma='auto').fit(train_x, train_y)\n",
    "    elif model_name == 'rvm':\n",
    "        model = EMRVR(kernel=\"rbf\", gamma='auto',verbose=True)\n",
    "        model.fit(train_x, train_y)\n",
    "        joblib.dump(model,'./model/15_minute/rvm_pred(cwb).pkl')\n",
    "    elif model_name == 'persistence':\n",
    "        test_x = scaler_x.inverse_transform(test_x)\n",
    "        test_x = test_x.reshape(-1)\n",
    "        test_y = test_y.reshape(-1)\n",
    "        test_idx['pred'] = test_x\n",
    "        test_idx['true'] = test_y\n",
    "        return test_idx\n",
    "\n",
    "\n",
    "\n",
    "#     other_params = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,\n",
    "#     'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "#     model = xgb.XGBRegressor(**other_params).fit(train_x, train_y)\n",
    "\n",
    "# 預測\n",
    "    pred_y = model.predict(test_x)\n",
    "    \n",
    "    \n",
    "# 反正規劃\n",
    "    pred_y = pred_y.reshape(-1,1)\n",
    "    pred_y = scaler_y.inverse_transform(pred_y)\n",
    "    pred_y = pred_y.reshape(-1)\n",
    "    test_idx['pred'] = pred_y\n",
    "    test_idx['true'] = test_y\n",
    "    return test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b41319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def MAPE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def MRE(y_true, y_pred, capacity):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred))/capacity) * 100\n",
    "\n",
    "def nMAE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred))/y_true.mean() * 100\n",
    "\n",
    "def MAE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "def nRMSE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())/y_true.mean()*100\n",
    "\n",
    "def cRMSE(y_true, y_pred, capacity):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())/capacity*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7637a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear interpolation 線性插值\n",
    "from scipy.interpolate import interp1d\n",
    "def interpolate(x, kind='linear'):\n",
    "    not_nan = np.logical_not(np.isnan(x))\n",
    "    indices = np.arange(len(x))\n",
    "#     interp = interp1d(indices[not_nan], x[not_nan], kind=kind)\n",
    "    interp = interp1d(indices[not_nan], x[not_nan], kind=kind,fill_value=\"extrapolate\")\n",
    "    return interp(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2c1b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16167/16167 [12:33<00:00, 21.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 依據時間將15分鐘的發電資料和天氣資料合併\n",
    "# data = pd.read_csv('power_data/merge_alldata_15.csv')\n",
    "# data = data.rename(columns={'kP':'Power'})\n",
    "# data['hour'] = pd.to_datetime(data['TIME_TO_INTERVAL']).dt.hour\n",
    "# data['date'] = pd.to_datetime(data['TIME_TO_INTERVAL']).dt.date\n",
    "# data = data[['TIME_TO_INTERVAL','date','hour','Power']]\n",
    "# data = data.dropna(subset=['Power']).reset_index(drop=True)\n",
    "# data = data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\").reset_index(drop=True)\n",
    "# weatherdata = pd.read_csv('dataset/solar_汙水廠(history).csv')\n",
    "# weatherdata = weatherdata.rename(columns={'Radiation(SDv3)(IBM)':'Radiation(SDv3)(TWC)',\n",
    "#                                           'Radiation(MSM)':'Radiation(SDv3)(MSM)'})\n",
    "# weatherdata['hour'] = pd.to_datetime(weatherdata['TIME_TO_INTERVAL']).dt.hour\n",
    "# weatherdata['date'] = pd.to_datetime(weatherdata['TIME_TO_INTERVAL']).dt.date\n",
    "# weatherdata = weatherdata[['date','hour','Radiation','ClearSkyRadiation','Radiation(SDv3)(CWB)',\n",
    "#                            'Radiation(SDv3)(TWC)','Radiation(SDv3)(OWM)','Radiation(SDv3)(MSM)',\n",
    "#                            'Radiation(today)(CWB)','Radiation(today)(IBM)','Radiation(today)(OWM)']]\n",
    "# merge_data = pd.merge(data,weatherdata,on=['date','hour'],how='inner')\n",
    "# merge_data['minute'] = pd.to_datetime(merge_data['TIME_TO_INTERVAL']).dt.minute\n",
    "# merge_data = merge_data.drop_duplicates(['TIME_TO_INTERVAL'], keep=\"last\").reset_index(drop=True)\n",
    "# #對可能會有缺失值的欄位做線性差值\n",
    "# merge_data['Radiation(SDv3)(CWB)'] = interpolate(merge_data['Radiation(SDv3)(CWB)'].values)\n",
    "# merge_data['Radiation(SDv3)(TWC)'] = interpolate(merge_data['Radiation(SDv3)(TWC)'].values)\n",
    "# merge_data['Radiation(SDv3)(OWM)'] = interpolate(merge_data['Radiation(SDv3)(OWM)'].values)\n",
    "# merge_data['Radiation(SDv3)(MSM)'] = interpolate(merge_data['Radiation(SDv3)(MSM)'].values)\n",
    "# merge_data['ClearSkyRadiation'] = interpolate(merge_data['ClearSkyRadiation'].values)\n",
    "# merge_data['Radiation(SDv3)(MSM)'] = interpolate(merge_data['Radiation(SDv3)(MSM)'].values)\n",
    "# #因線性差值會有負數，所以將負數都已0取代\n",
    "# merge_data['Radiation(SDv3)(CWB)'] = merge_data['Radiation(SDv3)(CWB)'].where(merge_data['Radiation(SDv3)(CWB)'] >= 0, 0)\n",
    "# merge_data['Radiation(SDv3)(TWC)'] = merge_data['Radiation(SDv3)(TWC)'].where(merge_data['Radiation(SDv3)(TWC)'] >= 0, 0)\n",
    "# merge_data['Radiation(SDv3)(OWM)'] = merge_data['Radiation(SDv3)(OWM)'].where(merge_data['Radiation(SDv3)(OWM)'] >= 0, 0)\n",
    "# merge_data['Radiation(SDv3)(MSM)'] = merge_data['Radiation(SDv3)(MSM)'].where(merge_data['Radiation(SDv3)(MSM)'] >= 0, 0)\n",
    "# merge_data['ClearSkyRadiation'] = merge_data['ClearSkyRadiation'].where(merge_data['ClearSkyRadiation'] >= 0, 0)\n",
    "# merge_data['Radiation'] = merge_data['Radiation'].where(merge_data['Radiation'] >= 0, 0)\n",
    "\n",
    "# pre_datas = pd.DataFrame()\n",
    "# for i in tqdm(range(len(merge_data))):\n",
    "#     target_day = merge_data.loc[i:i].reset_index(drop=True)\n",
    "#     pre_data = split_data(merge_data,target_day)\n",
    "#     pre_datas = pd.concat([pre_datas,pre_data],axis=0)\n",
    "# pre_datas = pre_datas.fillna(0)    \n",
    "# pre_datas.reset_index(drop=True,inplace=True)\n",
    "# pre_datas\n",
    "# merge_data = merge_data.merge(pre_datas, how='left', left_index=True, right_index=True)\n",
    "# merge_data.to_csv('power_data/merge_weather_power_for_train15(cwb).csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data = pd.read_csv('power_data/merge_weather_power_for_train15.csv', low_memory=False)\n",
    "# merge_data['month'] = pd.to_datetime(merge_data ['TIME_TO_INTERVAL']).dt.month\n",
    "# merge_data = merge_data.drop( index = merge_data['pre_Power_15'][merge_data['pre_Power_15'] == 0].index )\n",
    "# merge_data = merge_data.drop( index = merge_data['pre_Power_30'][merge_data['pre_Power_30'] == 0].index )\n",
    "# merge_data = merge_data.drop( index = merge_data['pre_Power_45'][merge_data['pre_Power_45'] == 0].index )\n",
    "# merge_data = merge_data.drop( index = merge_data['pre_Radiation_15'][merge_data['pre_Radiation_15'] == 0].index )\n",
    "# merge_data = merge_data.drop( index = merge_data['Radiation_0'][merge_data['Radiation_0'] == 0].index )\n",
    "# merge_data = merge_data.drop( index = merge_data['next_Radiation_15'][merge_data['next_Radiation_15'] == 0].index )\n",
    "# merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0054f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.read_csv('power_data/merge_weather_power_for_train15(twc).csv', low_memory=False)\n",
    "merge_data['month'] = pd.to_datetime(merge_data ['TIME_TO_INTERVAL']).dt.month\n",
    "#刪除欄位中有0的值\n",
    "merge_data = merge_data.drop( index = merge_data['pre_Power_15'][merge_data['pre_Power_15'] == 0].index )\n",
    "merge_data = merge_data.drop( index = merge_data['pre_Power_30'][merge_data['pre_Power_30'] == 0].index )\n",
    "merge_data = merge_data.drop( index = merge_data['pre_Power_45'][merge_data['pre_Power_45'] == 0].index )\n",
    "merge_data = merge_data.drop( index = merge_data['pre_Radiation_15'][merge_data['pre_Radiation_15'] == 0].index )\n",
    "merge_data = merge_data.drop( index = merge_data['Radiation_0'][merge_data['Radiation_0'] == 0].index )\n",
    "merge_data = merge_data.drop( index = merge_data['next_Radiation_15'][merge_data['next_Radiation_15'] == 0].index )\n",
    "feature = ['pre_Power_30','pre_Power_45','pre_Radiation_15','Radiation_0','next_Radiation_15','month']\n",
    "test_split_date = '2022-05-20'\n",
    "test_split_date_2 = '2022-09-15'\n",
    "anser = []\n",
    "# for i in range(len(feature)):\n",
    "for i in range(1):\n",
    "    #feature_data = ['pre_Power_15','next_Radiation_15','pre_Power_30']\n",
    "    feature_data =['pre_Power_15']\n",
    "#     feature_data.append(feature[i])\n",
    "    mask = merge_data['TIME_TO_INTERVAL']<=test_split_date\n",
    "    mask2 = merge_data['TIME_TO_INTERVAL']>test_split_date\n",
    "    mask3 = merge_data['TIME_TO_INTERVAL']<=test_split_date_2\n",
    "    train_data = merge_data[mask]\n",
    "    test_data = merge_data[(mask2&mask3)]\n",
    "    #print(test_data)\n",
    "    train_x = train_data[feature_data]\n",
    "    train_y = train_data[['Power']]\n",
    "    test_x = test_data[feature_data]\n",
    "    test_y = test_data[['Power']]\n",
    "    \n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_x.fit(train_x[feature_data])\n",
    "    train_x = scaler_x.transform(train_x[feature_data])\n",
    "    test_x = scaler_x.transform(test_x[feature_data])\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit(train_y[['Power']])\n",
    "    train_y = scaler_y.transform(train_y[['Power']])\n",
    "\n",
    "    train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "    test_x, test_y = np.array(test_x), np.array(test_y)\n",
    "    train_idx, test_idx = pd.DataFrame(), pd.DataFrame()  \n",
    "    pred = model_build(train_x, train_y, train_idx, test_x, test_y, test_idx, 'persistence')\n",
    "    anser.append(round(nRMSE(pred['true'], pred['pred']),2))\n",
    "    anser.append(round(nMAE(pred['true'], pred['pred']),2))\n",
    "    anser.append(round(RMSE(pred['true'], pred['pred']),2))\n",
    "    anser.append(round(MAE(pred['true'], pred['pred']),2))\n",
    "    print(round(nRMSE(pred['true'], pred['pred']),2))\n",
    "    print(round(nMAE(pred['true'], pred['pred']),2))\n",
    "    print(round(RMSE(pred['true'], pred['pred']),2))\n",
    "    print(round(MAE(pred['true'], pred['pred']),2))\n",
    "\n",
    "print(anser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(nRMSE(pred['true'], pred['pred']),2))\n",
    "# print(round(nMAE(pred['true'], pred['pred']),2))\n",
    "# print(round(RMSE(pred['true'], pred['pred']),2))\n",
    "# print(round(MAE(pred['true'], pred['pred']),2))\n",
    "\n",
    "line_color = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # cooked asparagus green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#8c564b',  # chestnut brown\n",
    "    '#e377c2',  # raspberry yogurt pink\n",
    "    '#7f7f7f',  # middle gray\n",
    "    '#bcbd22',  # curry yellow-green\n",
    "    '#17becf'   # blue-teal\n",
    "]\n",
    "\n",
    "\n",
    "xtick = int(len(test_data['TIME_TO_INTERVAL'])/96)\n",
    "\n",
    "fig_line = go.Figure()\n",
    "fig_line.add_trace(go.Scatter(y = pred['true'], x=test_data['TIME_TO_INTERVAL'],\n",
    "                    mode='lines',\n",
    "                    name='真實值',\n",
    "                    line={'dash': 'dash'},\n",
    "                    line_color= '#1f77b4'))\n",
    "fig_line.add_trace(go.Scatter(y = pred['pred'], x=test_data['TIME_TO_INTERVAL'],\n",
    "                    mode='lines',\n",
    "                    name='預測值',\n",
    "                    line_color= '#ff7f0e'))\n",
    "fig_line.update_layout(\n",
    "    yaxis_title='發電量',\n",
    "    xaxis_title='日期',\n",
    "    title='預測結果',\n",
    "    font=dict(\n",
    "        size=18,\n",
    "    ),\n",
    "#     yaxis2=dict(anchor='x', overlaying='y', side='right')\n",
    "    height=450, \n",
    "    width=1500,\n",
    "\n",
    ")\n",
    "\n",
    "fig_line.update_xaxes(nticks=xtick)\n",
    "\n",
    "\n",
    "#     fig_line.write_html(f'{folder_path}/img/{methods}_{i}.html')\n",
    "\n",
    "fig_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056c0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
